{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda\n",
      "NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Tokenizer, Wav2Vec2Model, Trainer, TrainingArguments\n",
    "import transformers\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import copy\n",
    "import math\n",
    "import librosa\n",
    "from pathlib import Path\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Running on device: {}'.format(device))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LaylarZhang\\anaconda3\\envs\\emotion\\lib\\site-packages\\transformers\\configuration_utils.py:349: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base were not used when initializing Wav2Vec2Model: ['quantizer.weight_proj.weight', 'project_hid.weight', 'project_q.weight', 'project_hid.bias', 'quantizer.weight_proj.bias', 'project_q.bias', 'quantizer.codevectors']\n",
      "- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wav2Vec2Model(\n",
      "  (feature_extractor): Wav2Vec2FeatureExtractor(\n",
      "    (conv_layers): ModuleList(\n",
      "      (0): Wav2Vec2GroupNormConvLayer(\n",
      "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
      "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1): Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      )\n",
      "      (2): Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      )\n",
      "      (3): Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      )\n",
      "      (4): Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "      )\n",
      "      (5): Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
      "      )\n",
      "      (6): Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feature_projection): Wav2Vec2FeatureProjection(\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): Wav2Vec2Encoder(\n",
      "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "      (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
      "      (padding): Wav2Vec2SamePadLayer()\n",
      "    )\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0): Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (6): Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (7): Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (8): Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (9): Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (10): Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (11): Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Model(\n",
       "  (feature_extractor): Wav2Vec2FeatureExtractor(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): Wav2Vec2GroupNormConvLayer(\n",
       "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (1): Wav2Vec2NoLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "      )\n",
       "      (2): Wav2Vec2NoLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "      )\n",
       "      (3): Wav2Vec2NoLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "      )\n",
       "      (4): Wav2Vec2NoLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "      )\n",
       "      (5): Wav2Vec2NoLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "      )\n",
       "      (6): Wav2Vec2NoLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feature_projection): Wav2Vec2FeatureProjection(\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): Wav2Vec2Encoder(\n",
       "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "      (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "      (padding): Wav2Vec2SamePadLayer()\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0): Wav2Vec2EncoderLayer(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Wav2Vec2EncoderLayer(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): Wav2Vec2EncoderLayer(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): Wav2Vec2EncoderLayer(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): Wav2Vec2EncoderLayer(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): Wav2Vec2EncoderLayer(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): Wav2Vec2EncoderLayer(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): Wav2Vec2EncoderLayer(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): Wav2Vec2EncoderLayer(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): Wav2Vec2EncoderLayer(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): Wav2Vec2EncoderLayer(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): Wav2Vec2EncoderLayer(\n",
       "        (attention): Wav2Vec2Attention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "# processor = AutoProcessor.from_pretrained(\"ydshieh/wav2vec2-large-xlsr-53-chinese-zh-cn-gpt\")\n",
    "# model = AutoModelForCTC.from_pretrained(\"ydshieh/wav2vec2-large-xlsr-53-chinese-zh-cn-gpt\")\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "print(model)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../dataset/chinese_dataset/'\n",
    "emotions = ['Angry', 'Happy', 'Neutral', 'Sad']\n",
    "OUTPUT = '../models/eng_chinese/'\n",
    "\n",
    "BATCHSIZE = 20\n",
    "EPOCHS = 30\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = lr_scheduler.StepLR(optimizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75520\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "all_dataset = []\n",
    "for i, emotion in enumerate(emotions):\n",
    "    filepath = Path(DATASET_PATH + emotion + '/')\n",
    "    for file in filepath.glob(\"*.wav\"): \n",
    "        wav, rate = librosa.load(file, sr=16000, mono=True, res_type=\"kaiser_fast\")\n",
    "        tensor = torch.tensor(wav, device=\"cuda\")\n",
    "        all_dataset.append((tensor, i))\n",
    "print(len(all_dataset[10][0]))\n",
    "print(len(all_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 25.64it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 26.81it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 24.45it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 23.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75520\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "root = glob.glob(DATASET_PATH + \"*\")\n",
    "for i, filepath in enumerate(root):\n",
    "    filepath = filepath.replace(\"\\\\\", \"/\")\n",
    "    all_wav = os.listdir(filepath)\n",
    "    wav_sample = random.sample(all_wav, 10)\n",
    "\n",
    "    for sample in tqdm(wav_sample):\n",
    "        file = f\"{filepath}/{sample}\"\n",
    "        # add noise\n",
    "        wav, rate = librosa.load(file, sr=16000, mono=True, res_type=\"kaiser_fast\")\n",
    "        wav_n = wav + 0.009*np.random.normal(0,1,len(wav))\n",
    "        tensor = torch.tensor(wav, device=\"cuda\")\n",
    "        all_dataset.append((tensor, i))\n",
    "\n",
    "print(len(all_dataset[10][0]))\n",
    "print(len(all_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_data(data_set):\n",
    "    indices = sorted(range(len(data_set)),\n",
    "                     key=lambda k: len(data_set[k][0]),\n",
    "                     reverse=True)\n",
    "    data_set = [data_set[i] for i in indices]\n",
    "    return data_set, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(all_dataset):\n",
    "    # Split dataset\n",
    "    data_size = len(all_dataset)\n",
    "    dataset_sizes = {\n",
    "    \"train\": int(data_size*0.8),\n",
    "    \"test\": int(data_size*0.2),\n",
    "    }\n",
    "\n",
    "    train_set, test_set = data.random_split(all_dataset, [dataset_sizes[\"train\"], dataset_sizes[\"test\"]])\n",
    "    # sort\n",
    "    sorted_train, train_indices = sort_data(train_set)\n",
    "    sorted_test, test_indices = sort_data(test_set)\n",
    "\n",
    "    def pad_tensor(vec, pad, dim):\n",
    "        pad_size = list(vec.shape)\n",
    "        pad_size[dim] = pad - vec.size(dim)\n",
    "        return torch.cat([vec, torch.zeros(*pad_size).cuda()], dim=dim)\n",
    "\n",
    "    def collate_fn(instances):\n",
    "        \n",
    "        max_len = max(map(lambda x: x[0].shape[0], instances))\n",
    "        batch = []\n",
    "        for (x,y) in instances:\n",
    "            batch.append((pad_tensor(x, pad=max_len, dim=-1), y))\n",
    "        \n",
    "        f = list(map(lambda x: x[0], batch))\n",
    "        l = list(map(lambda x: x[1], batch))\n",
    "        features = torch.stack(f, dim=0)\n",
    "        labels = torch.Tensor(l)\n",
    "        return (features, labels)\n",
    "\n",
    "    dataloaders = {\n",
    "        \"train\": torch.utils.data.DataLoader(sorted_train, batch_size=BATCHSIZE,  num_workers=0, drop_last=True, collate_fn=collate_fn),\n",
    "        \"test\": torch.utils.data.DataLoader(sorted_test, batch_size=BATCHSIZE,  num_workers=0, drop_last=True, collate_fn=collate_fn),\n",
    "    }\n",
    "\n",
    "    return dataloaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 40\n"
     ]
    }
   ],
   "source": [
    "dataloaders, dataset_sizes = split_data(all_dataset)\n",
    "print(dataset_sizes[\"train\"], dataset_sizes[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranferModel(nn.Module):\n",
    "\n",
    "  def __init__(self, wav2vec, n_classes):\n",
    "    super().__init__()\n",
    "    self.wav2vec = wav2vec\n",
    "    self.dropout = nn.Dropout(0.2)\n",
    "    self.linear = nn.Linear(768, n_classes)\n",
    "    self.device = device\n",
    "    self.to(self.device)\n",
    "\n",
    "  def forward(self, input_values, attention_mask=None):\n",
    "    x = self.wav2vec(input_values=input_values, attention_mask=attention_mask)\n",
    "    # print(x.last_hidden_state.shape)\n",
    "    x = x.last_hidden_state.mean(1)\n",
    "    # print(x.shape)\n",
    "    x = self.dropout(x)\n",
    "    x = self.linear(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (model, dataloaders, dataset_sizes, num_epochs, optimizer, scheduler, checkpoint=None):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    outputlist = {'train': {'loss':[], 'acc': []}, 'test': {'loss':[], 'acc': []}}\n",
    "\n",
    "    if checkpoint is None:\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_loss = math.inf\n",
    "        best_acc = 0.0\n",
    "    else:\n",
    "        print(\n",
    "            f'Test loss: {checkpoint[\"best_test_loss\"]}, Test accuracy: {checkpoint[\"best_test_accuracy\"]}')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        best_loss = checkpoint['best_test_loss']\n",
    "        best_acc = checkpoint['best_test_accuracy']\n",
    "\n",
    "    #start training\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('--' * 10)\n",
    "\n",
    "        for phase in [\"train\", \"test\"]:\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            \n",
    "            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = torch.tensor([i.long() for i in labels])\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    # print(\"outputs: \", outputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    # print(\"preds: \", preds)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward propogation and optimize in 'train' mode\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            #record the loss and accuracy for visualization\n",
    "            outputlist[phase]['loss'].append(epoch_loss)\n",
    "            outputlist[phase]['acc'].append(epoch_acc.cpu())\n",
    "\n",
    "            print('{} Loss: {:.4f} Accuracy: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # output test result\n",
    "            if phase == \"test\" and epoch_acc > best_acc:\n",
    "                print(f'New best model found!')\n",
    "                print(f'New record accuracy: {epoch_acc}, Previous record accuracy: {best_acc}')\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                if epoch_acc > 0.40: \n",
    "                    check_point_path = OUTPUT + \"epoch\" + str(epoch) + \".pth\"\n",
    "\n",
    "                    torch.save({'model_state_dict': model.state_dict(),\n",
    "                                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                                'best_test_loss': best_loss,\n",
    "                                'best_test_accuracy': best_acc,\n",
    "                                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                                }, check_point_path)\n",
    "\n",
    "    print('Best test Accuracy: {:.4f} Best test loss: {:.4f}'.format(best_acc, best_loss))\n",
    "\n",
    "    # load and return the best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, best_loss, best_acc, outputlist\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "--------------------\n",
      "train Loss: 1.6533 Accuracy: 0.2563\n",
      "test Loss: 1.3851 Accuracy: 0.3250\n",
      "New best model found!\n",
      "New record accuracy: 0.325, Previous record accuracy: 0.0\n",
      "Epoch 2/30\n",
      "--------------------\n",
      "train Loss: 1.4892 Accuracy: 0.1938\n",
      "test Loss: 1.4611 Accuracy: 0.2000\n",
      "Epoch 3/30\n",
      "--------------------\n",
      "train Loss: 1.4265 Accuracy: 0.2375\n",
      "test Loss: 1.3931 Accuracy: 0.2250\n",
      "Epoch 4/30\n",
      "--------------------\n",
      "train Loss: 1.4074 Accuracy: 0.2000\n",
      "test Loss: 1.4039 Accuracy: 0.2000\n",
      "Epoch 5/30\n",
      "--------------------\n",
      "train Loss: 1.3996 Accuracy: 0.2687\n",
      "test Loss: 1.4062 Accuracy: 0.2000\n",
      "Epoch 6/30\n",
      "--------------------\n",
      "train Loss: 1.3851 Accuracy: 0.2750\n",
      "test Loss: 1.4053 Accuracy: 0.2000\n",
      "Epoch 7/30\n",
      "--------------------\n",
      "train Loss: 1.3840 Accuracy: 0.2188\n",
      "test Loss: 1.4037 Accuracy: 0.2000\n",
      "Epoch 8/30\n",
      "--------------------\n",
      "train Loss: 1.3844 Accuracy: 0.2750\n",
      "test Loss: 1.4019 Accuracy: 0.2000\n",
      "Epoch 9/30\n",
      "--------------------\n",
      "train Loss: 1.3879 Accuracy: 0.2625\n",
      "test Loss: 1.4003 Accuracy: 0.2000\n",
      "Epoch 10/30\n",
      "--------------------\n",
      "train Loss: 1.3865 Accuracy: 0.2375\n",
      "test Loss: 1.3995 Accuracy: 0.2000\n",
      "Epoch 11/30\n",
      "--------------------\n",
      "train Loss: 1.3857 Accuracy: 0.2687\n",
      "test Loss: 1.3995 Accuracy: 0.2000\n",
      "Epoch 12/30\n",
      "--------------------\n",
      "train Loss: 1.3842 Accuracy: 0.2687\n",
      "test Loss: 1.3994 Accuracy: 0.2000\n",
      "Epoch 13/30\n",
      "--------------------\n",
      "train Loss: 1.3860 Accuracy: 0.3000\n",
      "test Loss: 1.3993 Accuracy: 0.2000\n",
      "Epoch 14/30\n",
      "--------------------\n",
      "train Loss: 1.3893 Accuracy: 0.2188\n",
      "test Loss: 1.3993 Accuracy: 0.2000\n",
      "Epoch 15/30\n",
      "--------------------\n",
      "train Loss: 1.3852 Accuracy: 0.2625\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 16/30\n",
      "--------------------\n",
      "train Loss: 1.3926 Accuracy: 0.1938\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 17/30\n",
      "--------------------\n",
      "train Loss: 1.3866 Accuracy: 0.3313\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 18/30\n",
      "--------------------\n",
      "train Loss: 1.3895 Accuracy: 0.2500\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 19/30\n",
      "--------------------\n",
      "train Loss: 1.3814 Accuracy: 0.2500\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 20/30\n",
      "--------------------\n",
      "train Loss: 1.3905 Accuracy: 0.2188\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 21/30\n",
      "--------------------\n",
      "train Loss: 1.3860 Accuracy: 0.2500\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 22/30\n",
      "--------------------\n",
      "train Loss: 1.3857 Accuracy: 0.2812\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 23/30\n",
      "--------------------\n",
      "train Loss: 1.3796 Accuracy: 0.2625\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 24/30\n",
      "--------------------\n",
      "train Loss: 1.3850 Accuracy: 0.2625\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 25/30\n",
      "--------------------\n",
      "train Loss: 1.3875 Accuracy: 0.2375\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 26/30\n",
      "--------------------\n",
      "train Loss: 1.3892 Accuracy: 0.2563\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 27/30\n",
      "--------------------\n",
      "train Loss: 1.3813 Accuracy: 0.2812\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 28/30\n",
      "--------------------\n",
      "train Loss: 1.3810 Accuracy: 0.3125\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 29/30\n",
      "--------------------\n",
      "train Loss: 1.3835 Accuracy: 0.2875\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Epoch 30/30\n",
      "--------------------\n",
      "train Loss: 1.3872 Accuracy: 0.2500\n",
      "test Loss: 1.3992 Accuracy: 0.2000\n",
      "Best test Accuracy: 0.3250 Best test loss: 1.3851\n"
     ]
    }
   ],
   "source": [
    "new_model = TranferModel(model, len(emotions))\n",
    "\n",
    "best_model, best_test_loss, best_test_acc, outputlist = train(\n",
    "    new_model, dataloaders, dataset_sizes, EPOCHS, optimizer, scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf7951b4c3296236920d27fffb3ba5561f6be415b272a9a64a7d3575e786e583"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('emotion': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
